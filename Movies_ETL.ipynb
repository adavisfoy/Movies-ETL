{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3736a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "# json library to extract the Wikipedia data\n",
    "import json\n",
    "\n",
    "# Pandas to create DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy library for converting data types\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a List of Dictionaries\n",
    "# Data needs to be cleaned before loading it into DataFrame\n",
    "# Below - wiki_movies_raw is a list of dictionaries\n",
    "\n",
    "with open ('wikipedia-movies.json', mode='r') as file: \n",
    "    wiki_movies_raw = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use len to see how many records were pulled in\n",
    "len(wiki_movies_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d632655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review a few individual records to make sure data isn't garbled\n",
    "# Remember - we're working with lists so will have to use index slices to select specific chunks of data\n",
    "\n",
    "# First 5 records\n",
    "wiki_movies_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cc214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 records\n",
    "wiki_movies_raw[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some records in the middle\n",
    "wiki_movies_raw[3600:3605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 2 data sets directly into DataFrames since they are already \"flat\" files w/ all rows filled in\n",
    "kaggle_metadata_df = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "ratings_df = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect kaggle metadata with head\n",
    "kaggle_metadata_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba23b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect kaggle metadata with tail\n",
    "kaggle_metadata_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the kaggle data by sampling a handful of rows randomly\n",
    "kaggle_metadata_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the ratings data with head\n",
    "ratings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the ratings data with tail\n",
    "ratings_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5873a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the ratings data by sampling a handful of rows randomly\n",
    "ratings_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58773848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn wiki_movies_raw into a DataFrame\n",
    "wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e665a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 193 columns is a lot of columns!\n",
    "# Convert the column names to a new list to see them more easily\n",
    "wiki_movies_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list comprehension to filter data \n",
    "# Using list comprehension to restrict only to those entries that have a director and an IMDb link\n",
    "wiki_movies = [movie for movie in wiki_movies_raw\n",
    "               if ('Director' in movie or 'Directed by' in movie) \n",
    "               and 'imdb_link' in movie\n",
    "              and 'No. of episodes' not in movie]\n",
    "len(wiki_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe from wiki_movies\n",
    "wiki_movies_v2_df = pd.DataFrame(wiki_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting showing that down to 78 columns. Better than 193 but not great.\n",
    "wiki_movies_v2_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41737f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_v2_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find movies that have a value for Arabic\n",
    "wiki_movies_v2_df[wiki_movies_v2_df['Arabic'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find movies that have a value for Arabic - get their urls to be able to visit Wiki\n",
    "wiki_movies_v2_df[wiki_movies_v2_df['Arabic'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b227c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns and go through them one-by-one to find all that hold alternate titles\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbf13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find movies that have a value for '' - get their urls to be able to visit Wiki\n",
    "wiki_movies_v2_df[wiki_movies_v2_df['Also known as'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Here is a complete list of columns that hold alternate title data: \n",
    "# Also known as, Arabic, Cantonese, Chinese, French, Hangul, Hebrew, Hepburn, Japanese, Literally,  \n",
    "# Mandarin, McCune–Reischauer, Original title, Polish,  Revised Romanization, Romanized, Russian, Simplified, Traditional, \n",
    "# Yiddish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our function to clean our movie data\n",
    "# Because the movies are dict and we want to make nondestrictive edits, make a copy of the incoming movie\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) # create a non-destrictive copy\n",
    "    alt_titles = {} # make an empty dict to hold alternative titles\n",
    "    \n",
    "    # Loop through a list of all alternative title keys\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        \n",
    "        # Check if the current key exists in the movie object\n",
    "        if key in movie:\n",
    "            \n",
    "            # remove the key-value pair with pop() and add to the alternative titles dictionary\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "        \n",
    "        # After looping through every key, add the alternative titles dict to the movie object.\n",
    "        if len(alt_titles) > 0:\n",
    "            movie['alt_titles'] = alt_titles\n",
    "            \n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list comprehension to make a list of cleaned movies\n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa796ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick up at 8.3.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
